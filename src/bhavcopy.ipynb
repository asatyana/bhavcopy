{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import zipfile\n",
    "import os\n",
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "username = 'trading'\n",
    "password = 'trading'\n",
    "dsn = 'localhost:1521/XE'\n",
    "table_name = 'TRADES'\n",
    "\n",
    "# Function to generate working day dates between two dates\n",
    "def generate_working_day_urls(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    urls = []\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        if current_date.weekday() < 5:  # Weekdays (Monday to Friday)\n",
    "            formatted_date = current_date.strftime(\"%Y/%b/%d\").upper()\n",
    "            year, month, day = formatted_date.split('/')\n",
    "            url = f\"https://archives.nseindia.com/content/historical/EQUITIES/{year}/{month}/cm{day}{month}{year}bhav.csv.zip\"\n",
    "            urls.append(url)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return urls\n",
    "# End of function generate_working_day_urls\n",
    "\n",
    "# Function to get filename from the URL\n",
    "def get_filename_from_url(url):\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url)\n",
    "    # Extract the path component and split it to get the file name\n",
    "    file_name = parsed_url.path.split('/')[-1]\n",
    "    return file_name\n",
    "# End of function get_filename_from_url\n",
    "\n",
    "# Function to unzip the downloaded Bhavcopy zip file\n",
    "def unzip_file(zip_file_path, extract_to_folder=None):\n",
    "    if extract_to_folder is None:\n",
    "        extract_to_folder = os.path.dirname(zip_file_path)\n",
    "\n",
    "    # Extract the zip file contents\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to_folder)\n",
    "        print(f\"Extracted all files in {zip_file_path}\")\n",
    "# End of function unzip_file\n",
    "\n",
    "# Function to insert the data to DB\n",
    "def insert_data(data, table_name, username, password, dsn):\n",
    "    # Establish a database connection\n",
    "    connection = cx_Oracle.connect(username, password, dsn)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Calculate the percentage change\n",
    "    data[\"CHANGE_PCT\"] = round(((data[\"CLOSE\"] - data[\"PREVCLOSE\"]) / data[\"PREVCLOSE\"]) * 100, 2)\n",
    "\n",
    "    # Prepare insert query\n",
    "    placeholders = ', '.join([':' + str(i + 1) for i in range(len(data.columns))])\n",
    "    query = f\"INSERT INTO {table_name}  VALUES ({placeholders})\"\n",
    "\n",
    "    # Get the data to be inserted\n",
    "    rows = [tuple(x) for x in data.values]\n",
    "\n",
    "    # Execute insert statement\n",
    "    cursor.executemany(query, rows)\n",
    "\n",
    "    # Commit the transaction and close the connection\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"Data inserted successfully. \\n\")\n",
    "# End of function insert_data\n",
    "    \n",
    "\n",
    "# Main Processing\n",
    "\n",
    "# Define start and end dates (YYYY, MM, DD)\n",
    "start_date = datetime(2024, 2, 1)\n",
    "end_date = datetime.today()\n",
    "\n",
    "\n",
    "# Generate URLs\n",
    "urls = generate_working_day_urls(start_date, end_date)\n",
    "\n",
    "# Retreive Bhavcopy zip file from the URLs and insert to DB\n",
    "for url in urls:\n",
    "    response = requests.get(url, timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        # Write the content of the response to a local file\n",
    "        with open(get_filename_from_url(url), 'wb') as file:\n",
    "            file.write(response.content)\n",
    "            unzip_file(get_filename_from_url(url))\n",
    "            print(\"Downloaded: \" + get_filename_from_url(url))\n",
    "            tradeData = pd.read_csv(Path(get_filename_from_url(url)).stem,  keep_default_na=False, na_values=['_'])\n",
    "            tradeData.drop(0, axis=0, inplace=True)\n",
    "            tradeData.drop(columns=tradeData.columns[-1],  axis=1,  inplace=True)\n",
    "            print(\"Processing: \" + get_filename_from_url(url))\n",
    "\n",
    "            # Save data in DB\n",
    "            insert_data(tradeData, table_name, username, password, dsn)\n",
    "    else:\n",
    "        print(f\"Markets are closed due to public holiday\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
